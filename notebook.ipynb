{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of available GPUs: 1\n",
      "GPU 0 : NVIDIA GeForce RTX 2080 Ti\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '2'\n",
    "\n",
    "import torch\n",
    "\n",
    "# Check if CUDA is available\n",
    "if torch.cuda.is_available():\n",
    "    # Get the number of available GPUs\n",
    "    num_gpus = torch.cuda.device_count()\n",
    "    print(\"Number of available GPUs:\", num_gpus)\n",
    "\n",
    "    # Print the names of the visible GPUs\n",
    "    for i in range(num_gpus):\n",
    "        print(\"GPU\", i, \":\", torch.cuda.get_device_name(i))\n",
    "else:\n",
    "    print(\"CUDA is not available. Only CPU will be used.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d8ea296d87346d6acf6a5322db05a1a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSRVTT sim matrix size: 1000, 1000\n",
      "\t Length-T: 1000, Length-V:1000\n",
      "MSRVTT Text-to-Video:\n",
      "\t>>>  R@1: 44.9 - R@5: 67.9 - R@10: 77.2 - Median R: 2.0 - Mean R: 22.3\n",
      "MSRVTT Video-to-Text:\n",
      "\t>>>  V2T$R@1: 41.6 - V2T$R@5: 66.2 - V2T$R@10: 76.5 - V2T$Median R: 2.0 - V2T$Mean R: 22.5\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1'\n",
    "\n",
    "from easydict import EasyDict\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import os.path as osp\n",
    "from tqdm.auto import tqdm as tqdm\n",
    "from languagebind import LanguageBind, to_device, transform_dict, LanguageBindImageTokenizer\n",
    "from vl_ret.metrics import compute_metrics\n",
    "import sys\n",
    "\n",
    "\n",
    "class MyMSRVTT_DataLoader(Dataset):\n",
    "    \"\"\"MSRVTT dataset loader.\"\"\"\n",
    "    def __init__(\n",
    "            self,\n",
    "            csv_path,\n",
    "            features_path,\n",
    "    ):\n",
    "        self.data = pd.read_csv(csv_path)\n",
    "        self.features_path = features_path\n",
    "       \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        video_id = self.data['video_id'].values[idx]\n",
    "        sentence = self.data['sentence'].values[idx]\n",
    "\n",
    "        video_path = os.path.join(self.features_path, \"{}.mp4\".format(video_id))\n",
    "        return sentence, video_path\n",
    "\n",
    "def get_args_msrvtt():\n",
    "    # build args\n",
    "    args = {\n",
    "        \"val_csv\": '/raid/1moritz/datasets//MSRVTT/MSRVTT_JSFUSION_test.csv',\n",
    "        \"features_path\": '/raid/1moritz/datasets//MSRVTT/MSRVTT_Videos',\n",
    "        # \"max_words\": 77,\n",
    "        # \"feature_framerate\": 1,\n",
    "        # \"max_frames\": 8,\n",
    "        # \"eval_frame_order\": 0,\n",
    "        # \"slice_framepos\": 2,\n",
    "        \"batch_size_val\": 8,\n",
    "        \"num_thread_reader\": 1,\n",
    "        \"cache_dir\": '/raid/1moritz/models/languagebind/downloaded_weights',\n",
    "        # \"model\": 'laion/CLIP-ViT-L-14-DataComp.XL-s13B-b90K',\n",
    "    }\n",
    "    args = EasyDict(args)\n",
    "    return args\n",
    "\n",
    "def run_msrvtt_eval(model:LanguageBind, tokenizer:LanguageBindImageTokenizer, dataloader:DataLoader, modality_transform: dict, device: torch.device):\n",
    "    batch_sentences_embeddings, batch_videos_embeddings = [], []\n",
    "    # Calculate embeddings\n",
    "    for bid, batch in tqdm(enumerate(dataloader), total=len(dataloader)):\n",
    "        sentences, video_paths = batch\n",
    "\n",
    "        if not isinstance(sentences, list):\n",
    "            sentences = list(sentences)\n",
    "        if not isinstance(video_paths, list):\n",
    "            video_paths= list(video_paths)\n",
    "\n",
    "        # print(sentences)\n",
    "        # print(type(sentences))\n",
    "        # print(video_paths)\n",
    "        # print(type(video_paths))\n",
    "        # sys.exit()\n",
    "        inputs = {\n",
    "            'video': to_device(modality_transform['video'](video_paths), device),\n",
    "        }\n",
    "        inputs['language'] = to_device(tokenizer(sentences, max_length=77, padding='max_length',\n",
    "                                            truncation=True, return_tensors='pt'), device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            embeddings = model(inputs)\n",
    "\n",
    "        batch_sentences_embeddings.append(embeddings['language'])\n",
    "        batch_videos_embeddings.append(embeddings['video'])\n",
    "\n",
    "    # Create similarity matrix\n",
    "    sim_matrix = create_sim_matrix(batch_sentences_embeddings, batch_videos_embeddings)\n",
    "\n",
    "    # Log metrics\n",
    "    print(f\"MSRVTT sim matrix size: {sim_matrix.shape[0]}, {sim_matrix.shape[1]}\")\n",
    "    tv_metrics = compute_metrics(sim_matrix)\n",
    "    vt_metrics = compute_metrics(sim_matrix.T)\n",
    "    print('\\t Length-T: {}, Length-V:{}'.format(len(sim_matrix), len(sim_matrix[0])))\n",
    "\n",
    "    print(f\"MSRVTT Text-to-Video:\")\n",
    "    print('\\t>>>  R@1: {:.1f} - R@5: {:.1f} - R@10: {:.1f} - Median R: {:.1f} - Mean R: {:.1f}'.\n",
    "                format(tv_metrics['R1'], tv_metrics['R5'], tv_metrics['R10'], tv_metrics['MR'], tv_metrics['MeanR']))\n",
    "    print(f\"MSRVTT Video-to-Text:\")\n",
    "    print('\\t>>>  V2T$R@1: {:.1f} - V2T$R@5: {:.1f} - V2T$R@10: {:.1f} - V2T$Median R: {:.1f} - V2T$Mean R: {:.1f}'.\n",
    "                format(vt_metrics['R1'], vt_metrics['R5'], vt_metrics['R10'], vt_metrics['MR'], vt_metrics['MeanR']))\n",
    "\n",
    "def create_sim_matrix(batch_sentences_embeddings, batch_videos_embeddings):\n",
    "    \"\"\"Calculate embedding vector product for similarity and download result to CPU\n",
    "    \n",
    "        Returns: \n",
    "            sim_matrix (Text X Video)\n",
    "    \"\"\"\n",
    "    sim_matrix = []\n",
    "    for idx1 in range(len(batch_sentences_embeddings)):\n",
    "        sequence_output = batch_sentences_embeddings[idx1]\n",
    "        each_row = []\n",
    "        for idx2 in range(len(batch_videos_embeddings)):\n",
    "            visual_output = batch_videos_embeddings[idx2]\n",
    "            b1b2 =  sequence_output @ visual_output.T\n",
    "            b1b2 = b1b2.cpu().detach().numpy()\n",
    "            each_row.append(b1b2)\n",
    "        each_row = np.concatenate(tuple(each_row), axis=-1)\n",
    "        sim_matrix.append(each_row)\n",
    "    sim_matrix = np.concatenate(tuple(sim_matrix), axis=0)\n",
    "    return sim_matrix\n",
    "\n",
    "def main():\n",
    "    device = 'cuda:0'\n",
    "    device = torch.device(device)\n",
    "    clip_type = {\n",
    "        'video': 'LanguageBind_Video_FT',  # also LanguageBind_Video\n",
    "        'audio': 'LanguageBind_Audio_FT',  # also LanguageBind_Audio\n",
    "        'image': 'LanguageBind_Image',\n",
    "    }\n",
    "    args = get_args_msrvtt()\n",
    "\n",
    "    model = LanguageBind(clip_type=clip_type, cache_dir=args.cache_dir)\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    pretrained_ckpt = f'LanguageBind/LanguageBind_Image'\n",
    "    tokenizer = LanguageBindImageTokenizer.from_pretrained(pretrained_ckpt, cache_dir=osp.join(args.cache_dir, 'tokenizer_cache_dir'))\n",
    "    modality_transform = {c: transform_dict[c](model.modality_config[c]) for c in clip_type.keys()}\n",
    "\n",
    "    dataloader_msrvtt = DataLoader(\n",
    "        MyMSRVTT_DataLoader(csv_path=args.val_csv, features_path=args.features_path),\n",
    "        batch_size=args.batch_size_val,\n",
    "        num_workers=args.num_thread_reader,\n",
    "        shuffle=False,\n",
    "        drop_last=False,\n",
    "    )\n",
    "    run_msrvtt_eval(model, tokenizer, dataloader_msrvtt, modality_transform, device)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "languagebind",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
